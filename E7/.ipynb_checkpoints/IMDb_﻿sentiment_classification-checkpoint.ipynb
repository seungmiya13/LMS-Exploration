{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "global-instrumentation",
   "metadata": {},
   "source": [
    "IMDb 영화리뷰 감성분석\n",
    "======\n",
    "\n",
    "IMDb 데이터 셋을 이용하여 영어 텍스트의 감성분석 진행해보기 \n",
    "\n",
    "IMDb Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨이 달려 있습니다. 2011년 Learning Word Vectors for Sentiment Analysis 논문에서 이 데이터셋을 소개하였습니다.      \n",
    "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Faclanthology.org%2FP11-1015.pdf&clen=156182&chunk=true\n",
    "    \n",
    "50000개의 리뷰 중 절반인 25000개가 훈련용 데이터, 나머지 25000개를 테스트용 데이터로 사용하도록 지정되어 있습니다. 이 데이터셋은 tensorflow Keras 데이터셋 안에 포함되어 있어서 손쉽게 다운로드하여 사용할 수 있습니다.\n",
    "이후 스텝의 IMDb 데이터셋 처리 코드 중 일부는 Tensorflow 튜토리얼에 언급된 데이터 전처리 로직을 참고하였음을 밝힙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-olive",
   "metadata": {},
   "source": [
    "### 인코더 : 단어 -> 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outside-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medium-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수 \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "#encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "#print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-architecture",
   "metadata": {},
   "source": [
    "### 디코더 : 숫자 -> 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contrary-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수 \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "#print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hindu-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "#print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-litigation",
   "metadata": {},
   "source": [
    "## 1. IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-spanking",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-article",
   "metadata": {},
   "source": [
    "- imdb.load_data() 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blond-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 다운받은 실제 데이터 예시 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-virginia",
   "metadata": {},
   "source": [
    "- 텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있습니다.\n",
    "이미 텍스트가 encode되었으므로 IMDb 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tough-armenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-weapon",
   "metadata": {},
   "source": [
    "- word_to_index는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "#index_to_word[0] = \"<PAD>\"\n",
    "#index_to_word[1] = \"<BOS>\"\n",
    "#index_to_word[2] = \"<UNK>\"\n",
    "#index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "super-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88588\n",
      "88588\n"
     ]
    }
   ],
   "source": [
    "print(len(word_to_index))\n",
    "print(len(index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chronic-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# encode된 텍스트가 정상적으로 decode되는지 확인\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-bouquet",
   "metadata": {},
   "source": [
    "### 데이터셋의 문장의 길이 통일\n",
    "\n",
    "pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.\n",
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다. 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "olive-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "## 데이터셋 분포 확인\n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-guidance",
   "metadata": {},
   "source": [
    "-  list(x_train) , list(x_test) 를 사용하는 이유?     \n",
    "    https://chancoding.tistory.com/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quantitative-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "## 패딩 적용\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-cause",
   "metadata": {},
   "source": [
    "- 위의 경우에는 maxlen=580을 적용해줍니다.\n",
    "- 또 한가지 유의해야 하는 것은 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-patient",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-aquarium",
   "metadata": {},
   "source": [
    "## RNN model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-reduction",
   "metadata": {},
   "source": [
    "### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "african-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 \n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용, LSTM state 벡터의 차원수는 8로 \n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-block",
   "metadata": {},
   "source": [
    "### 검증셋 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaged-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-restaurant",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bulgarian-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 6s 110ms/step - loss: 0.6926 - accuracy: 0.5091 - val_loss: 0.6891 - val_accuracy: 0.5107\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6835 - accuracy: 0.5545 - val_loss: 0.6650 - val_accuracy: 0.6391\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.6320 - accuracy: 0.6865 - val_loss: 0.5287 - val_accuracy: 0.8115\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.5091 - accuracy: 0.8239 - val_loss: 0.4932 - val_accuracy: 0.8266\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.4225 - accuracy: 0.8756 - val_loss: 0.4465 - val_accuracy: 0.8446\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.3554 - accuracy: 0.9072 - val_loss: 0.4267 - val_accuracy: 0.8502\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.3054 - accuracy: 0.9189 - val_loss: 0.4070 - val_accuracy: 0.8540\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.2611 - accuracy: 0.9295 - val_loss: 0.3954 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 92ms/step - loss: 0.2220 - accuracy: 0.9401 - val_loss: 0.3955 - val_accuracy: 0.8427\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.1940 - accuracy: 0.9455 - val_loss: 0.4092 - val_accuracy: 0.8508\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.1727 - accuracy: 0.9522 - val_loss: 0.4208 - val_accuracy: 0.8470\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.1530 - accuracy: 0.9593 - val_loss: 0.4151 - val_accuracy: 0.8477\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.1354 - accuracy: 0.9659 - val_loss: 0.4281 - val_accuracy: 0.8495\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.1195 - accuracy: 0.9698 - val_loss: 0.4370 - val_accuracy: 0.8413\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.1165 - accuracy: 0.9710 - val_loss: 0.4582 - val_accuracy: 0.8326\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.1252 - accuracy: 0.9654 - val_loss: 0.4770 - val_accuracy: 0.8449\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.1094 - accuracy: 0.9713 - val_loss: 0.4700 - val_accuracy: 0.8444\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.1012 - accuracy: 0.9755 - val_loss: 0.4793 - val_accuracy: 0.8448\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.0857 - accuracy: 0.9801 - val_loss: 0.5082 - val_accuracy: 0.8473\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.0861 - accuracy: 0.9801 - val_loss: 0.5165 - val_accuracy: 0.8445\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-financing",
   "metadata": {},
   "source": [
    "###  train/validation loss, accuracy 확인\n",
    "     \n",
    "model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있습니다.    \n",
    "이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있는 좋은 자료가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "infectious-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "described-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "## Training loss & Validation loss 그래프 \n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-discrimination",
   "metadata": {},
   "source": [
    "- Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있습니다. validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더 이상의 트레이닝은 무의미해지게 마련입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "useful-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training accuracy & validation accuracy 그래프\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-cornell",
   "metadata": {},
   "source": [
    "- 마찬가지로 Training and validation accuracy를 그려 보아도 유사한 인사이트를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-senegal",
   "metadata": {},
   "source": [
    "### 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "challenging-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 17s - loss: 0.5581 - accuracy: 0.8334\n",
      "[0.5580523014068604, 0.8334400057792664]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-bulgarian",
   "metadata": {},
   "source": [
    "## 3. Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "assigned-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "utility-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/Exploration/E7/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "simple-winning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6.1321933e-02,  9.3696435e-05,  5.1338922e-02,  7.6066680e-02,\n",
       "        8.0556996e-02,  6.3979864e-02, -4.1001275e-02,  1.7482543e-02,\n",
       "        7.4509648e-03, -7.5460717e-02, -1.5144788e-02,  4.4574765e-03,\n",
       "       -4.2683538e-03, -4.9384896e-02, -4.2601783e-02, -3.7593115e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-colony",
   "metadata": {},
   "source": [
    "- gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "friendly-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crisp', 0.9547080993652344),\n",
       " ('bloom', 0.9425862431526184),\n",
       " ('challenges', 0.9406334757804871),\n",
       " ('dangers', 0.9397045969963074),\n",
       " ('impressed', 0.9394493103027344),\n",
       " ('informs', 0.9291202425956726),\n",
       " ('aunt', 0.9271728992462158),\n",
       " ('funniest', 0.9269301891326904),\n",
       " ('garnered', 0.9260446429252625),\n",
       " ('lunch', 0.9255810379981995)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하기\n",
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-accent",
   "metadata": {},
   "source": [
    "-  love라는 단어와 유사한 다른 단어를 그리 잘 찾았다고 느껴지지는 않습니다. 감성분류 태스크를 잠깐 학습한 것만으로 워드 벡터가 유의미하게 학습되기는 어려운 것 같습니다. 우리가 다룬 정도의 훈련데이터로는 워드 벡터를 정교하게 학습시키기 어렵습니다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-flexibility",
   "metadata": {},
   "source": [
    "### Google의 Word2Vec 모델\n",
    "\n",
    "구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용해 보겠습니다. Word2Vec은 무려 1억 개의 단어로 구성된 Google News dataset을 바탕으로 학습되었습니다. 총 300만 개의 단어를 각각 300차원의 벡터로 표현한 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "varied-squad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/Exploration/E7/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-basin",
   "metadata": {},
   "source": [
    "- 300dim의 벡터로 이루어진 300만 개의 단어입니다. 이 단어 사전을 메모리에 모두 로딩하면 아주 높은 확률로 여러분의 실습환경에 메모리 에러가 날 것입니다. 그래서 KeyedVectors.load_word2vec_format 메소드로 워드 벡터를 로딩할 때 가장 많이 사용되는 상위 100만 개만 limt으로 조건을 주어 로딩했습니다.\n",
    "- 메모리가 충분하다면 limt=None으로 하시면 300만 개를 모두 로딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "selected-tissue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-principle",
   "metadata": {},
   "source": [
    "- Word2Vec에서 제공하는 워드 임베딩 벡터들끼리는 의미적 유사도가 가까운 것이 서로 가깝게 제대로 학습된 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-syracuse",
   "metadata": {},
   "source": [
    "### 모델의 임베딩 레이어를 Word2Vec로 교체하여 다시 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "imperial-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "organic-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "worst-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 22s 552ms/step - loss: 0.7007 - accuracy: 0.5130 - val_loss: 0.6841 - val_accuracy: 0.5548\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.6671 - accuracy: 0.6040 - val_loss: 0.6482 - val_accuracy: 0.6357\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.6056 - accuracy: 0.6962 - val_loss: 0.5383 - val_accuracy: 0.7446\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.4550 - accuracy: 0.8105 - val_loss: 0.3873 - val_accuracy: 0.8272\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.3161 - accuracy: 0.8733 - val_loss: 0.3540 - val_accuracy: 0.8445\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.2372 - accuracy: 0.9143 - val_loss: 0.3337 - val_accuracy: 0.8547\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.1789 - accuracy: 0.9422 - val_loss: 0.3421 - val_accuracy: 0.8544\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.1290 - accuracy: 0.9649 - val_loss: 0.3355 - val_accuracy: 0.8612\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 11s 359ms/step - loss: 0.0952 - accuracy: 0.9778 - val_loss: 0.3465 - val_accuracy: 0.8610\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.0663 - accuracy: 0.9905 - val_loss: 0.3623 - val_accuracy: 0.8598\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 11s 358ms/step - loss: 0.0475 - accuracy: 0.9944 - val_loss: 0.3878 - val_accuracy: 0.8565\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 11s 357ms/step - loss: 0.0361 - accuracy: 0.9968 - val_loss: 0.4018 - val_accuracy: 0.8571\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 11s 363ms/step - loss: 0.0248 - accuracy: 0.9981 - val_loss: 0.4167 - val_accuracy: 0.8603\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 11s 368ms/step - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.4391 - val_accuracy: 0.8586\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 11s 370ms/step - loss: 0.0139 - accuracy: 0.9989 - val_loss: 0.4535 - val_accuracy: 0.8603\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 11s 371ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.4650 - val_accuracy: 0.8596\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 11s 369ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.4782 - val_accuracy: 0.8584\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 11s 370ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.4954 - val_accuracy: 0.8586\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 11s 368ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.5042 - val_accuracy: 0.8579\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 11s 370ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.5182 - val_accuracy: 0.8585\n"
     ]
    }
   ],
   "source": [
    "## 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "promising-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 11s - loss: 0.5715 - accuracy: 0.8455\n",
      "[0.5715458393096924, 0.84552001953125]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-proceeding",
   "metadata": {},
   "source": [
    "- Word2Vec을 정상적으로 잘 활용하면 그렇지 않은 경우보다 5% 이상의 성능향상이 발생합니다. 적절한 모델 구성, 하이퍼파라미터를 고려하여 감정분석 모델의 성능을 최대한으로 끌어올려 봅시다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
